{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvs = [\n",
    "    '~/dataset/train/train.csv',\n",
    "    '~/dataset/test/test_data.csv'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for csv in csvs:\n",
    "    dfs.append(pd.read_csv(csv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_entities(entities: pd.Series) -> pd.Series:\n",
    "    parsed = entities.apply(lambda entity: literal_eval(entity))\n",
    "    return parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dfs:\n",
    "    df.subject_entity = parse_entities(df.subject_entity)\n",
    "    df.object_entity = parse_entities(df.object_entity)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word, start_idx, end_idx, type\n",
    "def localize_entities(sentence: str, entity: dict):\n",
    "    return sentence[entity['start_idx']:entity['end_idx'] + 1] == entity['word']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dfs:\n",
    "    assert(df.apply(lambda row: localize_entities(row.sentence, row.subject_entity), axis=1).all())\n",
    "    assert(df.apply(lambda row: localize_entities(row.sentence, row.object_entity), axis=1).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~/dataset/train/train.csv\n",
      "PER    16786\n",
      "ORG    15684\n",
      "Name: subject_entity, dtype: int64\n",
      "PER    9788\n",
      "ORG    9346\n",
      "POH    5113\n",
      "DAT    4249\n",
      "LOC    3561\n",
      "NOH     413\n",
      "Name: object_entity, dtype: int64\n",
      "\n",
      "~/dataset/test/test_data.csv\n",
      "PER    3925\n",
      "ORG    3839\n",
      "LOC       1\n",
      "Name: subject_entity, dtype: int64\n",
      "POH    3171\n",
      "LOC    1204\n",
      "PER    1138\n",
      "ORG    1047\n",
      "DAT     790\n",
      "NOH     415\n",
      "Name: object_entity, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, df in enumerate(dfs):\n",
    "    print(csvs[i])\n",
    "    print(df.subject_entity.apply(lambda entity: entity['type']).value_counts())\n",
    "    print(df.object_entity.apply(lambda entity: entity['type']).value_counts())\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('klue-re')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "de90de2e169711c7f785391f4739966861b1923c71a9551176a1fa090cefce8f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
